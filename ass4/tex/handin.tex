\documentclass[a4paper,10pt]{article}
\usepackage[a4paper, total={210mm,297mm}, left=20mm, right=20mm, top=20mm, bottom=20mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{parskip}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\arabic{section}.\alph{subsection}}
\renewcommand\thesubsubsection{\arabic{section}.\alph{subsection}.\roman{subsubsection}}

%opening
\title{Assignment 4 \\ Cache coherence protocols and Interconnect networks \\ Programming Massively Parallel Hardware }
\author{Mads Thoudahl  /qmh332}

\begin{document}

\maketitle
\section{MSI / MESI performance gains}

\begin{table}[h]
  \centering
  \begin{tabular}{rccccc}
    Access & Action & Bus & State & Traffic [Bytes] & Time [cycles] \\ \hline
     1 & R1/X & PrRd / BusRd & 1I $\rightarrow$ 1S  & 6+32 & 40 \\
     2 & W1/X & PrWr / BusUpgr & 1S $\rightarrow$ 1M & 10 & 10 \\
     3 & W1/X & PrWr / - & 1M $\rightarrow$ 1M & 0 & 1 \\

     4 & R2/X & PrRd / BusRd & 2I $\rightarrow$ 2S  & 6+32 & 40 \\
       &      & BusRd / Flush & 1M $\rightarrow$ 1S & - & - \\
     5 & W2/X & PrWr / BusUpgr & 2S $\rightarrow$ 2M & 10 & 10 \\
       &      & BusRdX / - & 1S $\rightarrow$ 1I & - & - \\
     6 & W2/X & PrWr / - & 2M $\rightarrow$ 2M & 0 & 1 \\

     7 & R3/X & PrRd / BusRd & 3I $\rightarrow$ 3S  & 6+32 & 40 \\
       &      & BusRd / Flush & 2M $\rightarrow$ 2S & - & - \\
     8 & W3/X & PrWr / BusUpgr & 3S $\rightarrow$ 3M & 10 & 10 \\
       &      & BusRdX / - & 2S $\rightarrow$ 2I & - & - \\
     9 & W3/X & PrWr / - & 3M $\rightarrow$ 3M & 0 & 1 \\

    10 & R4/X & PrRd / BusRd & 4I $\rightarrow$ 4S  & 6+32 & 40 \\
       &      & BusRd / Flush & 3M $\rightarrow$ 3S & - & - \\
    11 & W4/X & PrWr / BusUpgr & 4S $\rightarrow$ 4M & 10 & 10 \\
       &      & BusRdX / - & 3S $\rightarrow$ 3I & - & - \\
    12 & W4/X & PrWr / - & 4M $\rightarrow$ 4M & 0 & 1 \\ \hline

    sum & & & & 192 & 204 \\ \hline \hline
  \end{tabular}
  \caption{Access sequence 1: MSI, performance table}
  \label{tab:msi_1}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{rccccc}
    Access & Action & Bus & State & Traffic [Bytes] & Time [cycles] \\ \hline
     1 & R1/X & PrRd / BusRd & 1I $\rightarrow$ 1E  & 6+32 & 40 \\
     2 & W1/X & PrWr / - & 1E $\rightarrow$ 1M & 0 & 1 \\
     3 & W1/X & PrWr / - & 1M $\rightarrow$ 1M & 0 & 1 \\

     4 & R2/X & PrRd / BusRd(S) & 2I $\rightarrow$ 2S  & 6+32 & 40 \\
       &      & BusRd / Flush & 1M $\rightarrow$ 1S & - & - \\

     5 & W2/X & PrWr / BusRdX & 2S $\rightarrow$ 2M & 10 & 10 \\
       &      & BusRdX / - & 1S $\rightarrow$ 1I & - & - \\

     6 & W2/X & PrWr / - & 2M $\rightarrow$ 2M & 0 & 1 \\

     7 & R3/X & PrRd / BusRd(S) & 3I $\rightarrow$ 3S  & 6+32 & 40 \\
       &      & BusRd / Flush & 2M $\rightarrow$ 2S & - & - \\
     8 & W3/X & PrWr / BusRdX & 3S $\rightarrow$ 3M & 10 & 10 \\
       &      & BusRdX / - & 2S $\rightarrow$ 2I & - & - \\
     9 & W3/X & PrWr / - & 3M $\rightarrow$ 3M & - & 1 \\

    10 & R4/X & PrRd / BusRd(S) & 4I $\rightarrow$ 4S  & 6+32 & 40 \\
       &      & BusRd / Flush & 3M $\rightarrow$ 3S & - & - \\
    11 & W4/X & PrWr / BusRdX & 4S $\rightarrow$ 4M & 10 & 10 \\
       &      & BusRdX / - & 3S $\rightarrow$ 3I & - & - \\
    12 & W4/X & PrWr / - & 4M $\rightarrow$ 4M & - & 1 \\ \hline

    sum & & & & 182 & 195 \\ \hline \hline
  \end{tabular}
  \caption{Access sequence 1: MESI, performance table}
  \label{tab:mesi_1}
\end{table}

\subsection{Compare cycles taken to execute access sequence}
As seen from the MSI table \ref{tab:msi_1} the cycles taken to complete is 205.
The MESI table \ref{tab:mesi_1} reveals a small improvement at 195 cycles.

\subsection{Compare traffic generated in access sequence}
The traffic is also slightly better in the MESI model as we transfer 182 bytes on the bus compared to 192 in the MSI model.


\newpage

\section{Migratory sharing detection}

\begin{table}[h!]
  \centering
  \begin{tabular}{rccccc}
    Access & Action & Bus & State & Traffic [Bytes] & Time [cycles] \\ \hline
     1 & R1/X & PrRd / BusRd & 1I $\rightarrow$ 1E  & 6+32 & 40 \\
     2 & W1/X & PrWr / BusUpgr & 1E $\rightarrow$ 1M & 1 & 10 \\

     3 & R2/X & PrRd / BusRd & 2I $\rightarrow$ 2S  & 6+32 & 40 \\
       &      & BusRd / Flush & 1M $\rightarrow$ 1S & - & - \\
     4 & W2/X & PrWr / BusUpgr & 2S $\rightarrow$ 2M & 10 & 10 \\
       &      & BusRdX / - & 1S $\rightarrow$ 1I & - & - \\

     5 & R3/X & PrRd / BusRd & 3I $\rightarrow$ 3S  & 6+32 & 40 \\
       &      & BusRd / Flush & 2M $\rightarrow$ 2S & - & - \\
     6 & W3/X & PrWr / BusUpgr & 3S $\rightarrow$ 3M & 10 & 10 \\
       &      & BusRdX / - & 2S $\rightarrow$ 2I & - & - \\

     7 & R4/X & PrRd / BusRd & 4I $\rightarrow$ 4S  & 6+32 & 40 \\
       &      & BusRd / Flush & 3M $\rightarrow$ 3S & - & - \\
     8 & W4/X & PrWr / BusUpgr & 4S $\rightarrow$ 4M & 10 & 10 \\
       &      & BusRdX / - & 3S $\rightarrow$ 3I & - & - \\ \hline

    sum & & & & 192 & 200 \\ \hline \hline
  \end{tabular}
  \caption{Access sequence 2: MESI, performance table}
  \label{tab:mesi_2}
\end{table}


\begin{table}[h!]
  \centering
  \begin{tabular}{rccccc}
    Access & Action & Bus & State & Traffic [Bytes] & Time [cycles] \\ \hline
     1 & R1/X & PrRd / BusRd & 1I $\rightarrow$ 1E  & 6+32 & 40 \\
     2 & W1/X & PrWr / BusUpgr & 1E $\rightarrow$ 1M & 1 & 10 \\

     3 & R2/X & PrRd / BusRd & 2I $\rightarrow$ 2S  & 6+32 & 40 \\
       &      & BusRd / Flush & 1M $\rightarrow$ 1S & - & - \\
       & ---- & --- MIGRATORY  & SHARING --- & --- DETEC & TED --- \\
     4 & W2/X & PrWr / BusUpgr & 2S $\rightarrow$ 2M & 10 & 10 \\
       &      & BusRdX / - & 1S $\rightarrow$ 1I & - & - \\

     5 & R3/X & PrRd / BusRdX & 3I $\rightarrow$ 3E  & 6+32 &  40 \\
       &      & BusRdX / Flush & 2M $\rightarrow$ 2I & - & - \\
     6 & W3/X & PrWr / BusUpgr & 3E $\rightarrow$ 3M & 1 & 1 \\

     7 & R4/X & PrRd / BusRdX & 4I $\rightarrow$ 4E  & 6+32 & 40 \\
       &      & BusRdX / Flush & 3M $\rightarrow$ 3I & - & - \\
     8 & W4/X & PrWr / BusUpgr & 4S $\rightarrow$ 4M & 1 & 1 \\ \hline

    sum & & & & 165 & 182 \\ \hline \hline
  \end{tabular}
  \caption{Access sequence 2: MESI w/migratory sharing, performance table}
  \label{tab:mesi_2_migration}
\end{table}

\subsection{Compare cycles taken to execute access sequence}
As seen from the MESI \ref{tab:mesi_2} table the cycles taken to complete is 200.
The MESI w/migratory sharing \ref{tab:mesi_2_migration} table reveals a 182 cycles. 9\% fewer clock cycles used.

\subsection{Compare traffic generated in access sequence}
As seen from the MESI \ref{tab:mesi_2} table the cycles taken to complete is 192.
The MESI w/migratory sharing \ref{tab:mesi_2_migration} table reveals 165 bytes of traffic. 14 \% less traffic generated.


\newpage


\section{Shared Memory Multiprocessor w/ MSI protocol}
\begin{table}[h!]
  \centering
  \begin{tabular}{|c|l|c|c|}
    \hline
    Time & Access       & hit/type & Ignorable \\ \hline
     1 & P1: Read/B1:A  & Cold     & No \\
     2 & P2: Read/B1:B  & Cold     & No \\
     3 & P3: Read/B1:C  & Cold     & No \\
     4 & P1: Write/B1:A & False Sharing & Yes \\
     5 & P3: Read/B2:D  & Cold     & No \\
     6 & P2: Read/B1:B  & False Sharing & Yes \\
     7 & P1: Write/B1:B & False Sharing & Yes \\
     8 & P3: Read/B1:C  & Replacement & No \\
     9 & P2: Read/B1:B  & True Sharing & No \\ \hline
  \end{tabular}
  \caption{Access sequence 3: MSI, Cache-miss classification}
  \label{tab:mesi_2_migration}
  Px is Processor x. Cx is Cache belonging to procesor x. Bx is cache line block.
\end{table}

\subsection{Classify Misses}
Classification with respect to Replacement, True Sharing, and False Sharing misses.

Cold misses are seen at time: $\lbrace 1,2,3,5 \rbrace$. \\
Replacement miss are only seen at time: $\lbrace 8 \rbrace$. \\
False Sharing are seen at times: $\lbrace 4,6,7 \rbrace$. \\
True Sharing miss are only seen at time: $\lbrace 9 \rbrace$.

\subsection{Ignorable and still correct}
If the cache missed could have been ignored and the execution would still have been guaranteed correct.

Cache miss could have been ignored: $\lbrace 4,6,7 \rbrace$. \\
Cache miss could NOT have been ignored: $\lbrace 1,2,3,5,8,9 \rbrace$. \\

\newpage

\section{Scalable MSI protocol for systems, where nodes include local memory}
In each situation we need to find out how many cycles are used, and how much traffic is induced on the bus.
I choose to look at the time as the latency (in cycles) thus stuff performed in parallel is not added to the cycle clount, but cycles used on local lookups in a node is counted in. 
The traffic on the other hand is the usage of network bandwith, so only interconnect network data is counted.

In each situation we need to handle a read-cache miss ...
as all situations are 'read-cache miss', we do not need exclusive acces, thus no invalidate commands are issued.

Only in subtask \ref{sec:dash} we need to address what the difference is when using standard (3 hops) vs. DASH (3 hops) protocol

In all solutions i refer to figure \ref{fig:task4_solutions} for explanatory thoughts...

\begin{figure}[h!]
 \centering
 \includegraphics[height=60 mm,keepaspectratio=true]{./img/system.jpg}
 \label{fig:4_system}
 \caption{visualized time / protocol intra/inter - node communication for coherence}
\end{figure}


\subsection{home node is same as requesting, clean memory copy}
Time (Latency): $100$ Cycles\qquad Traffic: $0$ Bytes


\subsection{home node is same as requesting, dirty memory copy}
Time (Latency): $270$ Cycles\qquad Traffic: $44$ Bytes

\subsection{home node is different from requesting, clean memory copy}
Time (Latency): $270$ Cycles\qquad Traffic: $44$ Bytes

\subsection{home node is same as requesting and same as remote, dirty memory copy}
Can this even happen?? I can not see how...
Time (Latency): $100$ Cycles\qquad Traffic: $0$ Bytes

\subsection{home node is different from requesting which is again different from remote node holding a dirty memory copy} \label{sec:dash}
Standard (4 hops) - Time (Latency): $490$ Cycles\qquad Traffic: $88$ Bytes \\
DASH (3 hops) - Time (Latency): $340$ Cycles\qquad Traffic: $56$ Bytes


\begin{figure}[h!]
 \centering
 \includegraphics[height=40 mm,keepaspectratio=true]{./img/a.jpg}
 \includegraphics[height=40 mm,keepaspectratio=true]{./img/b.jpg}
 \includegraphics[height=40 mm,keepaspectratio=true]{./img/c.jpg} \\
 \vspace{2mm}
 \includegraphics[height=40 mm,keepaspectratio=true]{./img/d.jpg}
 \includegraphics[height=40 mm,keepaspectratio=true]{./img/e-3.jpg}
 \includegraphics[height=40 mm,keepaspectratio=true]{./img/e-4.jpg}
 \caption{Reference thoughts for task 4}
 \label{fig:task4_solutions}
\end{figure}

\vfill

\section{16-by-16 Torus Interconnect Network Properties}
The number of nodes is thus $n^2 = 16^2 = 256$ in this network...
Determine following properties...

\subsection{Network Diameter}
The Network Diameter describes the worst case distance to communicate, and is for the n-by-n tori $n$.\\
$$ \text{Network Diameter is } n = 16$$.


\subsection{Bisection Bandwith}
The bisection bandwith determines potential bottlenecks in the network, by determining the 'min-cut'. The symmetry of the topologies studied, presents us with nice, easy describable properties in this area, compared to the generic graph problem. In the tori case: $$ \text{The bisection width is } 2n = 2*16 = 32$$. 

\subsection{Bandwith per node}
As I am in doubt of the question asked, my answer is to the number of connections to and from each node.
The torus topologi, is a 2d grid connected in 3 dimensions, thus locally the grid can be seen as 'flat', and each node has 4 neighbors, thus their own local switch with 4 ports.

\newpage

\section{Network Interconnection Topologies}

\subsection{at what scale does hypercube provide higher bisection width than tori}

Bisection width:  N is total number of nodes, k is dimensions of hypercube, n is sidelength in torus.\\

Hypercube: $ 2^{k-1} = N/2 $ as $ N = 2^k $ 

Tori (n-by-n tori): $ 2n = 2 \sqrt{N} $ as $ N = n^2 $

$$
   \frac{N}{2} > 2 \cdot \sqrt{N} \quad \Rightarrow \quad 
   \frac{N^2}{2^2} > 2^2 \cdot N \quad \Rightarrow \quad 
   \frac{N^2}{N} > 2^{2^2} \quad \Rightarrow \quad 
   N > 16 \iff  k > 4 \iff  n > 4
$$
So, the hypercube has a larger bisection bandwith when dimensionality is (strictly) larger than 4...
This is good if you live in a place with 5 or more dimensions...

\subsection{Network Diameter and Switch Degree}
As the topologies differ in their basic layout the natural number of nodes (bigger than $16$) is $25=5^2$ in the tori-, and $32=2^5$ in the hypercube topology.
 
\begin{table}[h!]
  \centering
  \begin{tabular}{|l|c|c|}
    \hline
    Topology $\backslash$ Trait & Network Diameter & Swich Degree \\ \hline
    Hypercube & $k = log N = log 32 = 5$ & $k = log N = log 32 = 5$  \\
    Tori & $ n = \sqrt{N} = \sqrt{25} = 5 $ & $ 4 $ \\ \hline
  \end{tabular}
  \caption{Table of performance with more nodes than bisection breakpoint}
  \label{tab:tori_vs_hypercube}
\end{table}


\subsection{Statement of the relative merits of the two topologies}
\paragraph{Switch Degree (SD - complexity, or number of ports at each switch)}
As the tori SD is constant, it is only the number of switches that grows in a faster, not the switch complexity (degree).
In the hypercube, for each new dimension added another way of switching is needed, making the SD grow.

\paragraph{Network Diameter (ND - the worst case routing distance)}
As the hypercube's ND grow at the rate of $k = \log_2 N$ it asymptotically grow slower than the tori which actually already has a slow ND growth rate at $\sqrt{N}$

\paragraph{Real world}
As the world we live in consist of 3 spatial dimensions, it will be comprised with severe penalties trying to construct topologies with more dimensions than 3, such as the hypercube. This is a surface of (or cube of) cubes can be laid out, resembling the higher dimensionality, but we have to draw wires in all sorts of directions to cope with the dimensionality lack. It will be ugly, and the non uniform wire distances will harass the clocking of the IN communication. This leads to the k-ary n-cube, which tries to make up for it...
\end{document}
